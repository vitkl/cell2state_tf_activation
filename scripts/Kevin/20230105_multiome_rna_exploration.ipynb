{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc \n",
    "import anndata\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define constants here \n",
    "#Current date format is YYYYMMDD with automatically updated date\n",
    "today = datetime.datetime.now().strftime(\"%Y%m%d\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1. Load .h5ad and mapping file </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_10x_output(file_path, smp_list, metadata=None, type = 'raw', umi_filter=5):\n",
    "    import os\n",
    "    \n",
    "    #Writing output from separate samples, processed using CellRanger, into a dictionary of Scanpy objects:\n",
    "    ad = {}\n",
    "\n",
    "    #Generate AnnData for each sample\n",
    "    for sample_name in smp_list:\n",
    "        path = file_path + sample_name\n",
    "        for i in os.listdir(path):\n",
    "            if type in i and 'h5' in i:\n",
    "                file = i\n",
    "        ad[sample_name] = sc.read_10x_h5(file_path + sample_name +'/'+file)\n",
    "        ad[sample_name].var.rename(columns = {'gene_ids':'ENSEMBL'}, inplace = True)\n",
    "        ad[sample_name].var['SYMBOL'] = ad[sample_name].var.index\n",
    "        ad[sample_name].var.index = ad[sample_name].var['ENSEMBL']\n",
    "        ad[sample_name].var.drop(columns=['ENSEMBL'], inplace=True)\n",
    "        #ad[sample_name].var_names_make_unique() \n",
    "        \n",
    "        \n",
    "        sc.pp.calculate_qc_metrics(ad[sample_name], inplace=True)\n",
    "        ad[sample_name] = ad[sample_name][ad[sample_name].obs['total_counts'] > umi_filter, :]\n",
    "        ad[sample_name].var['mt'] = [gene.startswith('mt-') \n",
    "                                     for gene in ad[sample_name].var['SYMBOL']]\n",
    "        ad[sample_name].obs['mt_frac'] = (ad[sample_name][:, \n",
    "               ad[sample_name].var['mt'].tolist()].X.sum(1).A.squeeze() \n",
    "                                          / ad[sample_name].obs['total_counts'])\n",
    "        \n",
    "        ad[sample_name].obs['sample'] = sample_name\n",
    "        ad[sample_name].obs['barcode'] = ad[sample_name].obs_names\n",
    "        ad[sample_name].obs_names = ad[sample_name].obs['sample']+\"_\"+ad[sample_name].obs['barcode']\n",
    "\n",
    "    #Merge AnnData objects from all the samples together    \n",
    "    from scipy.sparse import vstack\n",
    "    stack = vstack([ad[x].X for x in smp_list]) # stack data\n",
    "    adata = sc.AnnData(stack, var = ad[smp_list[0]].var)\n",
    "    adata.obs = pd.concat([ad[x].obs for x in smp_list], axis = 0)\n",
    "\n",
    "    if metadata is not None:\n",
    "        #Add cleaned metadata to the Anndata.obs table\n",
    "        obs_merged = pd.merge(left = adata.obs, right = metadata, \n",
    "                              how = \"left\", left_on=\"sample\", right_on=\"sample\")\n",
    "        obs_merged.index = obs_merged['sample']+\"_\"+obs_merged['barcode']\n",
    "        print(obs_merged.index.equals(adata.obs.index))\n",
    "        adata.obs = obs_merged\n",
    "\n",
    "    return adata, ad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a sample list in form of a dataframe to be concatenated by the read_10x_output function\n",
    "sample_list = pd.DataFrame({\n",
    "    'sample': ['cellranger710_count_05e682d5679826b9b76d6bec731bbe61']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/team205/kl11/miniconda3/envs/bcftools/lib/python3.9/site-packages/anndata/_core/anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/tmp/ipykernel_15134/435707439.py:23: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  ad[sample_name].var['mt'] = [gene.startswith('mt-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/team205/kl11/miniconda3/envs/bcftools/lib/python3.9/site-packages/anndata/_core/anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/tmp/ipykernel_15134/435707439.py:23: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  ad[sample_name].var['mt'] = [gene.startswith('mt-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Save results in the following folder (create if it doesn't exist)\n",
    "\n",
    "results_folder = '/lustre/scratch123/hgi/teams/parts/kl11/cell2state_tf_activation/results/'\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "    \n",
    "sc_data_folder = '/nfs/team205/vk7/sanger_projects/cell2state_tf_activation/data/pilot_5_prime_dec_2022/'\n",
    "\n",
    "#Read in 10x data in raw and filtered format\n",
    "adata, ad_list = read_10x_output(\n",
    "    sc_data_folder, \n",
    "    smp_list=sample_list['sample'],\n",
    "    metadata=sample_list, type = 'raw')\n",
    "# export aggregated and pre-processed data\n",
    "# adata.write(f'{results_folder}{today}_all_cells_with_empty.h5ad')\n",
    "\n",
    "adata, ad_list = read_10x_output(\n",
    "    sc_data_folder, \n",
    "    smp_list=sample_list['sample'],\n",
    "    metadata=sample_list, type = 'filtered')\n",
    "# export aggregated and pre-processed data\n",
    "# adata.write(f'{results_folder}{today}_all_cells.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in sgRNA sequences to count reads per guide\n",
    "sgrna_df=pd.read_csv(f'{sc_data_folder}cellranger710_count_05e682d5679826b9b76d6bec731bbe61/feature_reference.csv')\n",
    "#Append additional sgRNA sequences that were not included in the data by appending rows to the dataframe\n",
    "sgrna_rest_df = pd.DataFrame(\n",
    "    [[\n",
    "        \"sgRNA1_SCP_CGAGTGTTCGATCGCGACTG_sgRNA1_SCP_CGAGTGTTCGATCGCGACTG_2\",\n",
    "        \"sgRNA1_SCP_CGAGTGTTCGATCGCGACTG_sgRNA1_SCP_CGAGTGTTCGATCGCGACTG_2\",\n",
    "        \"R2\",\n",
    "        \"TGCTGTTTCCAGCATAGCTCTTAAAC(BC)\",\n",
    "        \"AGTCGCGATCGAACACTCGC\",\n",
    "        \"CRISPR Guide Capture\"\n",
    "        ],\n",
    "    [\n",
    "        \"sgRNA6_SCP_GCAGACGTGCCTACGGACCG_sgRNA6_SCP_GCAGACGTGCCTACGGACCG_2\",\n",
    "        \"sgRNA6_SCP_GCAGACGTGCCTACGGACCG_sgRNA6_SCP_GCAGACGTGCCTACGGACCG_2\",\n",
    "        \"R2\",\n",
    "        \"TGCTGTTTCCAGCATAGCTCTTAAAC(BC)\",\n",
    "        \"CGGTCCGTAGGCACGTCTGC\",\n",
    "        \"CRISPR Guide Capture\"]],\n",
    "    columns= sgrna_df.columns\n",
    ")\n",
    "#rowwise concatenation of the two dataframes\n",
    "sgrna_df = pd.concat([sgrna_df, sgrna_rest_df], axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_cells(\n",
    "    adata,\n",
    "    cells_per_category=10000,\n",
    "    stratify_category_key='sample',\n",
    "):\n",
    "    \n",
    "    adata.obs['_cell_index'] = np.arange(adata.n_obs)\n",
    "    subset_ind = list()\n",
    "    \n",
    "    for ct in adata.obs[stratify_category_key].unique():\n",
    "        ind = adata.obs[stratify_category_key] == ct\n",
    "        subset_ind_ = adata.obs['_cell_index'][ind]\n",
    "        n_samples = np.min((len(subset_ind_), cells_per_category))\n",
    "        subset_ind = subset_ind + list(np.random.choice(subset_ind_, size=n_samples, replace=False))\n",
    "    print(len(subset_ind))\n",
    "    \n",
    "    return adata[subset_ind, :].copy()\n",
    "\n",
    "def compute_pcs_knn_umap(\n",
    "    adata_subset, stratify_category_key='sample', \n",
    "    tech_category_key=None, plot_category_keys=list(), \n",
    "    scale_max_value=10, n_comps=100, n_neighbors=15,\n",
    "):\n",
    "    adata_subset.obs['total_counts'] = np.array(adata_subset.X.sum(1)).flatten()\n",
    "    adata_subset.layers['counts'] = adata_subset.X.copy()\n",
    "    # No normalisation by total count\n",
    "    sc.pp.log1p(adata_subset)\n",
    "    # Scale with no HVG selection\n",
    "    if tech_category_key is None:\n",
    "        sc.pp.scale(adata_subset, max_value=scale_max_value)\n",
    "    else:\n",
    "        for tech in adata_subset.obs[tech_category_key].unique():\n",
    "            mu, std = compute_mu_std(adata_subset[adata_subset.obs[tech_category_key] == tech].X)\n",
    "            adata_subset[adata_subset.obs[tech_category_key] == tech].X = (\n",
    "                np.minimum((adata_subset[adata_subset.obs[tech_category_key] == tech].X - mu) / std, scale_max_value)\n",
    "            )\n",
    "    # A lot of PC dimensions\n",
    "    sc.tl.pca(adata_subset, svd_solver='arpack', n_comps=n_comps, use_highly_variable=False)\n",
    "    # Plot PCs to confirm that PC1 is indeed linked to total count\n",
    "    # sc.pl.pca(adata_subset, color=['total_counts'],\n",
    "    #           components=['1,2', '2,3', '4,5'],\n",
    "    #           color_map = 'RdPu', ncols = 3, legend_loc='on data',\n",
    "    #           legend_fontsize=10)\n",
    "    plt.hist2d(adata_subset.obsm['X_pca'][:, 0].flatten(),\n",
    "               adata_subset.obs['total_counts'].values.flatten(),\n",
    "               bins=200,\n",
    "               norm=mpl.colors.LogNorm());\n",
    "    plt.xlabel('PC 1');\n",
    "    plt.ylabel('Total RNA count');\n",
    "    plt.show()\n",
    "\n",
    "    # Remove PC1\n",
    "    adata_subset.obsm['X_pca'] = adata_subset.obsm['X_pca'][:, 1:]\n",
    "    adata_subset.varm['PCs'] = adata_subset.varm['PCs'][:, 1:]\n",
    "\n",
    "    # compute KNN and UMAP to see how well this represents the dataset\n",
    "    sc.pp.neighbors(adata_subset, n_neighbors=n_neighbors)\n",
    "    sc.tl.umap(adata_subset, min_dist = 0.4, spread = 1.5)\n",
    "\n",
    "    # Plot UMAP\n",
    "    sc.pl.umap(adata_subset, color=[stratify_category_key] + plot_category_keys,\n",
    "               color_map = 'RdPu', ncols = 3, #legend_loc='on data',\n",
    "               legend_fontsize=10)\n",
    "    return adata_subset\n",
    "\n",
    "def compute_mu_std(X):\n",
    "        \n",
    "    mu = np.array(X.mean(0))\n",
    "    mu_sq = mu ** 2\n",
    "    X = X.copy()\n",
    "    X.data = X.data ** 2\n",
    "    sq_mu = np.array(X.mean(0))\n",
    "    std = np.sqrt(sq_mu - mu_sq) + 1e-8\n",
    "    \n",
    "    return mu, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell2state",
   "language": "python",
   "name": "cell2state_tf_activation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
